{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8b0cce",
   "metadata": {},
   "source": [
    "<h2> Introduction </h2>\n",
    "\n",
    "In this kernel, we will use Gausian Process Regressions and Bayesian Optimisation on ecoacoustic metrics to quantify the spatiotemporal distribution of birds on-farm. The data was obtained by placing 20 audio recorders across the property in a grid formation. The biodiversity project was set up in 14 and 15th Nov 2019.\n",
    "\n",
    "\n",
    "<h2> Our Goals </h2>\n",
    "\n",
    "<ul>\n",
    "<li> Understand the spatial and temporal variability in the data, in particular, study how avian species richness change, examine if there are seasonal cycles.\n",
    "<li> Determine the optimal placement of the 20 audio recorders using the previously described methods. </li>\n",
    "<li> Determine what the optimal placement would be if one or more of the recorders were to stop functioning. </li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<h2> Outline </h2>\n",
    "\n",
    "I. <b>Our Toolbox</b><br>\n",
    "a) [The PreProcessing Class](#preprocessingclass)<br>\n",
    "b) [The SingleFrameGaussianProcessModel Class](#singlegpclass)<br>\n",
    "c) [The FullGaussianProcessModel Class](#fullgpclass)<br>\n",
    "d) [The TSModel Class](#tsmodelclass)<br>\n",
    "e) [The Visualise Class](#visualiseclass)<br>\n",
    "\n",
    "II. <b>Understanding our data</b><br>\n",
    "a) [Gathering sense of our data](#gather)<br>\n",
    "\n",
    "\n",
    "III. <b>Gaussian Process Regression spatiotemporal predictions</b><br>\n",
    "a) [Picture: single timeframe spatial gaussian process regression predictions](#singlegp)<br>\n",
    "b) [Video: spatiotemporal gaussian process regression predictions over the whole timeframe](#fullgp)<br>\n",
    "\n",
    "\n",
    "IV. <b>Understanding the spatial and temporal variability in avian richness</b><br>\n",
    "a) [Timeseries analysis](#tsmodel)<br>\n",
    "b) [Spatiotemporal analysis?](#spatiotemporal)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import statsmodels.api as sm\n",
    "from itertools import product\n",
    "import datetime as dt\n",
    "from os.path import exists\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afc800",
   "metadata": {},
   "source": [
    "<h2> I. Our Toolbox </h2>\n",
    "<a id=\"preprocessingclass\"></a>\n",
    "\n",
    "<h3>a) The PreProcessing Class</h3>\n",
    "\n",
    "-Explanation here-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595e9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing:\n",
    "    def __init__(self,data_name,metadata_name,data_type):\n",
    "        self.instrument_data = pd.read_csv(data_name)\n",
    "        self.instrument_metadata = pd.read_csv(metadata_name)\n",
    "        self.names = np.unique(self.instrument_data['name'])\n",
    "        self.formatted_data = self.format_data(data_type)\n",
    "        self.current_data = self.formatted_data\n",
    "        self.get_metadata()\n",
    "        \n",
    "    def get_metadata(self):\n",
    "        metadata = self.instrument_metadata.set_index('instrument_name').sort_index()\n",
    "        self.current_metadata = metadata.loc[self.names]\n",
    "        return self.current_metadata\n",
    "        \n",
    "    def get_names(self):\n",
    "        return list(self.current_data.columns)\n",
    "    \n",
    "    def get_single_frame_data(self,data,index):        \n",
    "        data = data.iloc[index]\n",
    "        lats,longs = [],[]\n",
    "        for name in self.names:\n",
    "            lats.append(self.current_metadata['latitude'][name])\n",
    "            longs.append(self.current_metadata['longitude'][name])\n",
    "\n",
    "        single_frame_data = pd.DataFrame({'long':longs,'lat':lats,'val':data.values})\n",
    "        \n",
    "        return single_frame_data\n",
    "    \n",
    "    def get_data_for_full_gp(self,data):\n",
    "        \n",
    "        lats, longs, times,vals = [],[],[],[]\n",
    "        \n",
    "        for name in self.names:\n",
    "            for time in data[name].index:\n",
    "                lats.append(self.current_metadata['latitude'][name])\n",
    "                longs.append(self.current_metadata['longitude'][name])\n",
    "                times.append(time)\n",
    "                vals.append(data[name][time])\n",
    "                \n",
    "        data_for_gp = pd.DataFrame({'long':longs,'lat':lats,'time':times,'val':vals})\n",
    "        data_for_gp['time'] = data_for_gp.time.apply(lambda x: dt.datetime.timestamp(dt.datetime(x.year,x.month,x.day)))\n",
    "        \n",
    "        return data_for_gp\n",
    "    \n",
    "    def get_single_site_data(self,data,name):\n",
    "        return data[name]\n",
    "        \n",
    "    def format_data(self,data_type):\n",
    "        diversity_index = self.instrument_data[self.instrument_data['type']==data_type]\n",
    "        self.all_times = np.unique(diversity_index['timeStart'])\n",
    "        \n",
    "        grouped = diversity_index.groupby(['timeStart','name'], as_index=False).sum()\n",
    "        grouped = grouped.drop('instrument_id', axis=1)\n",
    "        pivoted = grouped.pivot(index=\"timeStart\", columns=\"name\").reset_index(drop=True)\n",
    "        formatted_data = pivoted.droplevel(level=0, axis=1)\n",
    "        formatted_data.columns.name = None\n",
    "        formatted_data.fillna(0, inplace=True)\n",
    "\n",
    "        return formatted_data\n",
    "    \n",
    "    def remove_plot(self):\n",
    "#         This could be improved upon by looking at the intersections\n",
    "        max_num_zeros = 0\n",
    "        name_max_num_zeros = ''\n",
    "        for name in self.names:\n",
    "            num_zeros = (self.current_data[name]==0).sum()\n",
    "            if num_zeros > max_num_zeros:\n",
    "                max_num_zeros = num_zeros\n",
    "                name_max_num_zeros = name\n",
    "        self.current_data = self.current_data.drop(columns = [name_max_num_zeros])\n",
    "        self.names = self.get_names()\n",
    "        \n",
    "    def get_sections(self,current_data,name):\n",
    "        bool_zeros = current_data[:][name].values==0\n",
    "        toggle = 2\n",
    "        toggle_array=[]\n",
    "        non_zero_sections = []\n",
    "        zero_sections = []\n",
    "        for i in range(bool_zeros.size):\n",
    "            if toggle!=bool_zeros[i]:\n",
    "                toggle = bool_zeros[i]\n",
    "                toggle_array.append(i)\n",
    "                if toggle and len(toggle_array)>1:\n",
    "                    non_zero_sections.append([toggle_array[-2],i])\n",
    "                elif not toggle and len(toggle_array)>2:\n",
    "                    zero_sections.append([toggle_array[-2],toggle_array[-1]])\n",
    "            if i == bool_zeros.size-1:\n",
    "                if toggle:\n",
    "                    zero_sections.append([toggle_array[-1],i])\n",
    "                else:\n",
    "                    non_zero_sections.append([toggle_array[-1],i])\n",
    "\n",
    "        return non_zero_sections,zero_sections\n",
    "\n",
    "    def get_overlapping_intersections(self,current_data):\n",
    "        all_non_zero_sections = []\n",
    "        for name in self.names:\n",
    "            _,zero_sections = self.get_sections(current_data,name)\n",
    "            for i in range(len(zero_sections)):\n",
    "                len_section = zero_sections[i][1]-zero_sections[i][0] + 1\n",
    "                if len_section < 20:\n",
    "                    self.current_data[name][zero_sections[i][0]:zero_sections[i][1]] = np.nan\n",
    "\n",
    "            non_zero_sections,_ = self.get_sections(current_data,name)\n",
    "            all_non_zero_sections.append(non_zero_sections)           \n",
    "        intersections = self.get_intersections(all_non_zero_sections)\n",
    "        return intersections\n",
    "\n",
    "    def get_intersection(self,range_1,range_2):\n",
    "        x = range(range_1[0],range_1[1])\n",
    "        y = range(range_2[0],range_2[1])\n",
    "        xs = set(x)\n",
    "        inter = xs.intersection(y)\n",
    "        if len(inter) == 0:\n",
    "            return []\n",
    "        return [min(list(inter)),max(list(inter))+1]\n",
    "\n",
    "    def get_intersections(self,all_non_zero_sections):\n",
    "        final_set = []\n",
    "        for i in range(len(all_non_zero_sections[0])):\n",
    "            base_set = [all_non_zero_sections[0][i]]\n",
    "            if len(all_non_zero_sections)>1:\n",
    "                for j in range(1,len(all_non_zero_sections)):\n",
    "                    new_set = []\n",
    "                    # Loop over values in base_set\n",
    "                    for k in range(len(base_set)):\n",
    "                        # Loop over values in each section\n",
    "                        for l in range(len(all_non_zero_sections[j])):\n",
    "                            inter = self.get_intersection(base_set[k],all_non_zero_sections[j][l])\n",
    "                            if len(inter) != 0:\n",
    "                                new_set.append(inter)\n",
    "                    base_set = new_set\n",
    "            for b_set in base_set:\n",
    "                final_set.append(b_set)\n",
    "        return final_set\n",
    "    \n",
    "    def get_current_cleaned_data(self):\n",
    "        ranges = self.get_overlapping_intersections(self.current_data)\n",
    "        diff_r = []\n",
    "        for r in ranges:\n",
    "            diff_r.append(r[1]-r[0])\n",
    "        max_range_idx = np.argmax(diff_r)\n",
    "        cleaned_data = self.current_data.iloc[ranges[max_range_idx][0]:ranges[max_range_idx][1]]\n",
    "        cleaned_and_interpolated_data = self.interpolate_data(cleaned_data)\n",
    "        self.current_cleaned_data = cleaned_data\n",
    "        \n",
    "        cleaned_data['time'] = self.all_times[ranges[max_range_idx][0]:ranges[max_range_idx][1]]\n",
    "        cleaned_data = cleaned_data.set_index('time')\n",
    "\n",
    "        return cleaned_data\n",
    "    \n",
    "    def interpolate_data(self,data):\n",
    "        for name in self.names:\n",
    "            data[name] = data[name].interpolate()\n",
    "        return data\n",
    "    \n",
    "    def get_current_cleaned_date_data(self,df):\n",
    "        df = df.reset_index()\n",
    "        df['time'] = df['time'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "        df['time'] = df.time.dt.date\n",
    "        self.current_cleaned_date_data = df.groupby('time', as_index=False).mean().set_index('time')\n",
    "        return self.current_cleaned_date_data\n",
    "    \n",
    "    def get_av_period(self,df):\n",
    "        df = df.reset_index()\n",
    "        df['time'] = df['time'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "        df['time'] = df.time.dt.date\n",
    "        df = df.groupby('time', as_index=False).count()\n",
    "        df = df['A01']\n",
    "        return int(np.round(np.mean(df.values),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82be4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PreProcessing('data/instrument_data.csv','data/instrument_metadata.csv','ADI')\n",
    "preprocessor.remove_plot()\n",
    "metadata = preprocessor.get_metadata()\n",
    "ecoacoustic_data = preprocessor.get_current_cleaned_data()\n",
    "ecoacoustic_date_data = preprocessor.get_current_cleaned_date_data(ecoacoustic_data)\n",
    "period = preprocessor.get_av_period(ecoacoustic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73426a3a",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"singlegpclass\"></a>\n",
    "\n",
    "<h3>b) The SingleFrameGaussianProcessModel class</h3>\n",
    "\n",
    "-Explanation here-\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"fullgpclass\"></a>\n",
    "\n",
    "<h3>c) The FullGaussianProcessModel class</h3>\n",
    "\n",
    "-Explanation here-\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"tsmodelclass\"></a>\n",
    "\n",
    "<h3>d) The TSModel class</h3>\n",
    "\n",
    "-Explanation here-\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"visualiseclass\"></a>\n",
    "\n",
    "<h3>e) The Visualise class</h3>\n",
    "\n",
    "-Explanation here-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3e19b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcoacousticModel:\n",
    "    def __init__(self):\n",
    "        print('Initializing Model')\n",
    "        \n",
    "    def save_results(fig,filename):\n",
    "        if exists(filename):\n",
    "            print('This file already exists')\n",
    "        else:\n",
    "            fig.savefig(filename)\n",
    "\n",
    "class SingleFrameGaussianProcessModel(EcoacousticModel):   \n",
    "    def __init__(self, single_frame_data,n_points = 100):\n",
    "#         filename = \n",
    "        super().__init__()\n",
    "        self.n_points = n_points\n",
    "\n",
    "        self.X = single_frame_data[['long','lat']].values\n",
    "        self.y = single_frame_data.val.values\n",
    "\n",
    "        # Input space\n",
    "        x1 = np.linspace(np.min(single_frame_data.long), np.max(single_frame_data.long),n_points) #p\n",
    "        x2 = np.linspace(np.min(single_frame_data.lat), np.max(single_frame_data.lat),n_points) #q\n",
    "        self.x = (np.array([x1, x2])).T\n",
    "        self.x1x2 = np.array(list(product(x1, x2)))\n",
    "        self.X0p, self.X1p = self.x1x2[:,0].reshape(n_points,n_points), self.x1x2[:,1].reshape(n_points,n_points)\n",
    "\n",
    "\n",
    "        kernel = RBF([5,5], (1e-2, 1e2))\n",
    "        self.gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=15)\n",
    "\n",
    "    def run(self):\n",
    "        self.gp.fit(self.X, self.y)\n",
    "\n",
    "        self.y_pred, self.MSE = self.gp.predict(self.x1x2, return_std=True)\n",
    "\n",
    "        self.y_lower = self.y_pred - 2*self.MSE\n",
    "        self.y_higher = self.y_pred + 2*self.MSE\n",
    "\n",
    "        Zp_mean = np.reshape(self.y_pred,(self.n_points,self.n_points))\n",
    "        Zp_lower = np.reshape(self.y_lower,(self.n_points,self.n_points))\n",
    "        Zp_higher = np.reshape(self.y_higher,(self.n_points,self.n_points))\n",
    "\n",
    "        self.vmin = np.min(self.y_lower)\n",
    "        self.vmax = np.max(self.y_higher)\n",
    "\n",
    "        fig, ax = plt.subplots(1,3,figsize=(20,4))\n",
    "\n",
    "        im = ax[1].pcolormesh(self.X0p, self.X1p, Zp_mean,vmin=self.vmin,vmax=self.vmax,cmap='RdBu_r')\n",
    "        ax[1].title.set_text('μ')\n",
    "        ax[1].set_xlabel('Longitude')\n",
    "        ax[1].set_ylabel('Latitude')\n",
    "        \n",
    "        ax[0].pcolormesh(self.X0p, self.X1p, Zp_lower,vmin=self.vmin,vmax=self.vmax,cmap='RdBu_r')\n",
    "        ax[0].title.set_text('-2σ')\n",
    "        ax[0].set_xlabel('Longitude')\n",
    "        ax[0].set_ylabel('Latitude')\n",
    "        \n",
    "        ax[2].pcolormesh(self.X0p, self.X1p, Zp_higher,vmin=self.vmin,vmax=self.vmax,cmap='RdBu_r')\n",
    "        ax[2].title.set_text('+2σ')\n",
    "        ax[2].set_xlabel('Longitude')\n",
    "        ax[2].set_ylabel('Latitude')\n",
    "        \n",
    "        plt.suptitle('Time')\n",
    "        plt.show()\n",
    "        \n",
    "class FullGaussianProcessModel(EcoacousticModel): \n",
    "#         filename = \n",
    "    def __init__(self, date_for_gp, n_points = 50):\n",
    "        super().__init__()\n",
    "        self.n_points = n_points\n",
    "\n",
    "        self.X = data_for_gp[['long','lat','time']].values\n",
    "        self.y = data_for_gp.val.values\n",
    "\n",
    "        # Input space\n",
    "        x1 = np.linspace(np.min(data_for_gp.long), np.max(data_for_gp.long),n_points) #p\n",
    "        x2 = np.linspace(np.min(data_for_gp.lat), np.max(data_for_gp.lat),n_points) #q\n",
    "        x3 = np.linspace(np.min(data_for_gp.time), np.max(data_for_gp.time),n_points) #q\n",
    "\n",
    "        self.x1x2x3 = np.array(list(product(x1, x2, x3)))\n",
    "\n",
    "        self.gp = GaussianProcessRegressor(n_restarts_optimizer=15)\n",
    "    \n",
    "    def process_prediction(self):\n",
    "        self.y_pred, self.MSE = self.gp.predict(self.x1x2x3, return_std=True)\n",
    "\n",
    "        self.y_lower = self.y_pred - 2*self.MSE\n",
    "        self.y_higher = self.y_pred + 2*self.MSE\n",
    "\n",
    "        \n",
    "        \n",
    "        #pred_df = pd.DataFrame({'long':self.X[:,0],'lat':self.X[:,1],'time':self.X[:,2],'mean':self.y_pred,'lower':self.y_lower,'higher':self.y_higher})\n",
    "        pred_df = pd.DataFrame({'y_pred':self.y_pred,'y_lower':self.y_lower,'y_higher':self.y_higher})\n",
    "        cov_df = pd.DataFrame({'long':self.X[:,0],'lat':self.X[:,1],'time':self.X[:,2]})\n",
    "        \n",
    "        return cov_df\n",
    "        \n",
    "    def run(self):\n",
    "        self.gp.fit(self.X, self.y)\n",
    "\n",
    "        self.y_pred, self.MSE = self.gp.predict(self.x1x2x3, return_std=True)\n",
    "\n",
    "        self.y_lower = self.y_pred - 2*self.MSE\n",
    "        self.y_higher = self.y_pred + 2*self.MSE\n",
    "\n",
    "        self.vmin = np.min(self.y_lower)\n",
    "        self.vmax = np.max(self.y_higher)\n",
    "        \n",
    "        self.process_prediction(self.x1x2x3,self.y_pred,self.y_lower,self.y_higher)\n",
    "        \n",
    "        \n",
    "class TSModel(EcoacousticModel): \n",
    "#         filename = \n",
    "    def __init__(self, single_site_data, period):\n",
    "        super().__init__() \n",
    "        self.period = period\n",
    "        \n",
    "        self.single_site_data = single_site_data\n",
    "        self.seasonal_decompose(self.single_site_data)\n",
    "        \n",
    "    def seasonal_decompose(self,data):\n",
    "        decomposition = sm.tsa.seasonal_decompose(data.values, model='additive',extrapolate_trend='freq',period=self.period)\n",
    "        fig = decomposition.plot()\n",
    "        fig.set_size_inches(14,7)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0268315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.845310</td>\n",
       "      <td>-30.262051</td>\n",
       "      <td>1.573736e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149.845310</td>\n",
       "      <td>-30.262051</td>\n",
       "      <td>1.573823e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149.845310</td>\n",
       "      <td>-30.262051</td>\n",
       "      <td>1.573909e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.845310</td>\n",
       "      <td>-30.262051</td>\n",
       "      <td>1.573996e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149.845310</td>\n",
       "      <td>-30.262051</td>\n",
       "      <td>1.574082e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>149.892071</td>\n",
       "      <td>-30.259092</td>\n",
       "      <td>1.577020e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>149.892071</td>\n",
       "      <td>-30.259092</td>\n",
       "      <td>1.577106e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>149.892071</td>\n",
       "      <td>-30.259092</td>\n",
       "      <td>1.577192e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>149.892071</td>\n",
       "      <td>-30.259092</td>\n",
       "      <td>1.577279e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>149.892071</td>\n",
       "      <td>-30.259092</td>\n",
       "      <td>1.577365e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>817 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           long        lat          time\n",
       "0    149.845310 -30.262051  1.573736e+09\n",
       "1    149.845310 -30.262051  1.573823e+09\n",
       "2    149.845310 -30.262051  1.573909e+09\n",
       "3    149.845310 -30.262051  1.573996e+09\n",
       "4    149.845310 -30.262051  1.574082e+09\n",
       "..          ...        ...           ...\n",
       "812  149.892071 -30.259092  1.577020e+09\n",
       "813  149.892071 -30.259092  1.577106e+09\n",
       "814  149.892071 -30.259092  1.577192e+09\n",
       "815  149.892071 -30.259092  1.577279e+09\n",
       "816  149.892071 -30.259092  1.577365e+09\n",
       "\n",
       "[817 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FullGaussianProcessModel(data_for_gp).process_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf9d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model\n"
     ]
    }
   ],
   "source": [
    "data_for_gp = preprocessor.get_data_for_full_gp(ecoacoustic_date_data)\n",
    "FullGaussianProcessModel(data_for_gp).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41894dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    single_frame_data = preprocessor.get_single_frame_data(ecoacoustic_data,i)\n",
    "    SingleFrameGaussianProcessModel(single_frame_data).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualise:\n",
    "    def __init__(self,ecoacustic_data,metadata):\n",
    "        self.ecoacoustic_data = ecoacoustic_data\n",
    "        self.names = list(self.ecoacoustic_data.columns)\n",
    "        \n",
    "    def plot_all_ts(self):\n",
    "        for name in self.names:\n",
    "            plt.figure(figsize=(15, 3))\n",
    "            plt.plot(self.ecoacoustic_data[name].values)\n",
    "            plt.title(name)\n",
    "            plt.show()\n",
    "    \n",
    "    def point_animation(self):    \n",
    "        fig,ax = plt.subplots()\n",
    "\n",
    "        lats = []\n",
    "        longs = []\n",
    "        for name in self.names:\n",
    "            lats.append(self.metadata['latitude'][name])\n",
    "            longs.append(self.metadata['longitude'][name])\n",
    "\n",
    "        scatter = ax.scatter(longs, lats,s=np.zeros(len(self.names)))\n",
    "\n",
    "        def init():\n",
    "            scatter.set_sizes(np.zeros(len(self.names)))\n",
    "            return scatter\n",
    "\n",
    "        def update(frame):\n",
    "            data = frame\n",
    "            scatter.set_sizes(data*100)\n",
    "            return scatter\n",
    "\n",
    "        anim = FuncAnimation(fig, update, interval=1,frames = self.ecoacoustic_data.values,init_func=init)\n",
    "        \n",
    "        filename = 'results/animations/animation_of_' + str(len(self.names)) + '_plots.gif'\n",
    "        anim.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb868f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualiser = Visualise(ecoacoustic_data,metadata)\n",
    "visualiser.plot_all_ts()\n",
    "visualiser.point_animation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3ab7d",
   "metadata": {},
   "source": [
    "<h2> II. Understanding our data </h2>\n",
    "<a id=\"gathering\"></a>\n",
    "\n",
    "<h3>a) Gathering sense of our data</h3>\n",
    "\n",
    "-Explanation here-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503a838",
   "metadata": {},
   "source": [
    "<h2> III. Gaussian Process Regression spatiotemporal predictions </h2>\n",
    "<a id=\"singlegp\"></a>\n",
    "\n",
    "<h3>a) Picture: single timeframe spatial gaussian process regression predictions</h3>\n",
    "\n",
    "-Explanation here-\n",
    "\n",
    "\n",
    "<a id=\"fullgp\"></a>\n",
    "\n",
    "<h3>a) Video: spatiotemporal gaussian process regression predictions over the whole timeframe</h3>\n",
    "\n",
    "-Explanation here-\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0616b",
   "metadata": {},
   "source": [
    "<h2> IV. Understanding the spatial and temporal variability in avian richness </h2>\n",
    "<a id=\"tsmodel\"></a>\n",
    "\n",
    "<h3>a) Timeseries analysis </h3>\n",
    "\n",
    "-Explanation here-\n",
    "\n",
    "<a id=\"spatiotemporal\"></a>\n",
    "\n",
    "<h3>a) Spatiotemporal analysis </h3>\n",
    "\n",
    "-Explanation here-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
